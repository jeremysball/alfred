# Alfred - The Rememberer

**A persistent memory-augmented LLM assistant that remembers conversations across sessions, learns user preferences over time, and builds genuine understanding through accumulated context.**

---

## Vision

Existing LLM assistants start fresh every conversation. Users repeat themselves, lose context, and cannot build lasting relationships. Alfred solves this by maintaining persistent memory that grows richer over time.

**Core concept:** Alfred runs locally, speaks through Telegram or CLI, and uses a file-based memory system with dual vector embeddings for semantic retrieval.

---

## Design Principles

1. **Model-Driven Intelligence** â€” When Alfred makes decisionsâ€”what to remember, how to respond, which tool to useâ€”the LLM decides. Prefer prompting over programming.

2. **Zero-Command Interface** â€” Users speak naturally. "What did we discuss about my project?" triggers semantic search automatically. No `/commands` required for core functionality.

3. **Fail Fast** â€” Errors surface immediately. Silent failures hide bugs. Memories without embeddings are rejected.

4. **Streaming First** â€” Users see responses in real-time. Tool execution happens visibly. No waiting for complete responses.

---

## Technical Architecture

### Technology Stack
- **Runtime**: Python 3.12+ with `uv`
- **Interfaces**: Telegram Bot API (async), CLI
- **Container**: Docker with Tailscale networking
- **Storage**: JSONL files with OpenAI embeddings
- **Search**: Cosine similarity on vector embeddings

### File Structure
```
alfred/
â”œâ”€â”€ templates/            # Context templates (copied to data/ on first run)
â”‚   â”œâ”€â”€ AGENTS.md
â”‚   â”œâ”€â”€ SOUL.md
â”‚   â”œâ”€â”€ USER.md
â”‚   â”œâ”€â”€ TOOLS.md
â”‚   â””â”€â”€ MEMORY.md
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ alfred.py         # Core engine
â”‚   â”œâ”€â”€ agent.py          # Streaming agent loop
â”‚   â”œâ”€â”€ llm.py            # Provider abstraction (Kimi)
â”‚   â”œâ”€â”€ memory.py         # Memory store (JSONL + embeddings)
â”‚   â”œâ”€â”€ session.py        # Session management
â”‚   â”œâ”€â”€ context.py        # Context assembly
â”‚   â”œâ”€â”€ embeddings.py     # OpenAI embeddings
â”‚   â”œâ”€â”€ search.py         # Semantic search
â”‚   â”œâ”€â”€ templates.py      # Template auto-creation
â”‚   â”œâ”€â”€ cron/             # Cron jobs
â”‚   â”‚   â”œâ”€â”€ scheduler.py
â”‚   â”‚   â”œâ”€â”€ executor.py
â”‚   â”‚   â”œâ”€â”€ store.py
â”‚   â”‚   â””â”€â”€ notifier.py
â”‚   â”œâ”€â”€ tools/            # Tool implementations
â”‚   â”‚   â”œâ”€â”€ base.py       # Tool abstract class
â”‚   â”‚   â”œâ”€â”€ read.py       # File reading
â”‚   â”‚   â”œâ”€â”€ write.py      # File writing
â”‚   â”‚   â”œâ”€â”€ edit.py       # File editing
â”‚   â”‚   â”œâ”€â”€ bash.py       # Shell execution
â”‚   â”‚   â”œâ”€â”€ remember.py   # Save to memory
â”‚   â”‚   â”œâ”€â”€ search_memories.py
â”‚   â”‚   â”œâ”€â”€ update_memory.py
â”‚   â”‚   â”œâ”€â”€ forget.py     # Delete memories
â”‚   â”‚   â”œâ”€â”€ schedule_job.py
â”‚   â”‚   â”œâ”€â”€ list_jobs.py
â”‚   â”‚   â”œâ”€â”€ approve_job.py
â”‚   â”‚   â””â”€â”€ reject_job.py
â”‚   â””â”€â”€ interfaces/
â”‚       â”œâ”€â”€ cli.py        # CLI interface
â”‚       â””â”€â”€ telegram.py   # Telegram bot
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ memory/
â”‚   â”‚   â””â”€â”€ memories.jsonl    # Curated facts with embeddings
â”‚   â”œâ”€â”€ sessions/             # Session storage (PRD #76)
â”‚   â”‚   â””â”€â”€ {session_id}/
â”‚   â”‚       â”œâ”€â”€ messages.jsonl    # Session messages with embeddings
â”‚   â”‚       â””â”€â”€ summary.json      # Session summary + embedding
â”‚   â”œâ”€â”€ cron.jsonl            # Scheduled jobs
â”‚   â”œâ”€â”€ cron_history.jsonl    # Job execution history
â”‚   â”œâ”€â”€ cron_logs.jsonl       # Job output logs
â”‚   â”œâ”€â”€ AGENTS.md             # Agent behavior rules
â”‚   â”œâ”€â”€ SOUL.md               # Alfred's personality
â”‚   â”œâ”€â”€ USER.md               # User preferences
â”‚   â””â”€â”€ TOOLS.md              # Tool definitions
â””â”€â”€ tests/
```

---

## Memory Systems

Alfred uses a three-layer memory architecture:

```
data/
â”œâ”€â”€ memory/
â”‚   â””â”€â”€ memories.jsonl      # Layer 1: Curated facts
â”‚
â””â”€â”€ sessions/
    â””â”€â”€ {session_id}/
        â”œâ”€â”€ messages.jsonl  # Layer 3: Session messages
        â””â”€â”€ summary.json    # Layer 2: Session summary
```

### Layer 1: Curated Memory (Implemented)
Facts Alfred explicitly remembers:
- Alfred uses `remember` tool to store important information
- Stored in `data/memory/memories.jsonl` with embeddings
- Semantic search via `search_memories` tool
- Full CRUD: create, read, update, delete operations
- Can link to sessions via optional `session_id` field

### Layer 2: Session Summaries (PRD #76)
Narrative summaries of conversations:
- Auto-generated via cron (30 min idle or 20 messages)
- Stored in `data/sessions/{session_id}/summary.json`
- Has embedding for semantic search
- Enables finding past conversations by theme

### Layer 3: Session Messages (PRD #77)
Individual messages within sessions:
- Stored in `data/sessions/{session_id}/messages.jsonl`
- Each message has embedding
- Enables contextual narrowing: find session first, then search within

### Session History (In-Memory)
Current conversation context:
- Stored in `SessionManager` singleton during active session
- Injected into every LLM call for multi-turn conversation
- Persisted to session folders (PRD #76)

### Curated Memory (MEMORY.md)
Manually curated long-term insights:
- Loaded into every context
- Edited directly or via prompts

See PRDs #76 and #77 for contextual retrieval details.

---

## Roadmap

### Completed âœ…

| Milestone | Description |
|-----------|-------------|
| M1 | Project Setup - Repository structure, tooling, CI/CD |
| M2 | Core Infrastructure - Configuration, context loading, prompt assembly |
| M3 | Memory Foundation - JSONL storage with embeddings |
| M4 | Vector Search - Semantic memory retrieval |
| M5 | Telegram Bot - Multi-user chat interface with CLI |
| M6 | Kimi Provider - Integration with Moonshot AI's Kimi API |
| M7 | Personality & Context - SOUL.md, USER.md, context assembly |
| M8 | Tool System - Built-in tools with Pydantic schemas |
| M9 | Agent Loop - Streaming with tool execution |
| M10 | Memory System V2 - Full CRUD operations |
| M11 | PyPI Trusted Publishing - Automated package distribution |
| M12 | Rich Markdown Output - Streaming markdown rendering with Rich Live for CLI |

### In Progress / Next Up ðŸ”¨

| # | Milestone | Description |
|---|-----------|-------------|
| 12 | Session Summarization | Cron-based auto-summarization (30 min idle or 20 messages) |
| 13 | Learning System | Prompt-based learning to update USER.md/SOUL.md |
| 14 | Cron Error Handling & UX | Friendly errors, local timezone, CLI responsiveness |
| 15 | README Landing Page | Transform README into compelling OSS landing page |

### Short-term ðŸ“‹

| # | Milestone | Description |
|---|-----------|-------------|
| 17 | Testing & Quality | Comprehensive test coverage, fix deprecation warnings |
| 18 | Edit Tool Safety | Exact text matching validation, pre-edit verification |
| 19 | Test Configuration | Skip integration/e2e by default, separate CI jobs |
| 20 | Type Safety | Fix Tool class type safety, complete type annotations |
| 21 | Code Quality | Auto-fix Ruff violations, manual lint fixes |

### Medium-term ðŸ“…

| # | Milestone | Description |
|---|-----------|-------------|
| 22 | Advanced Session Features | LLM context control, substring search, on-demand summaries |
| 23 | Contextual Retrieval System | Triple-layer memory: global + session summaries + per-session message embeddings (PRD #77) |
| 24 | Configurable Context Budget | User-defined context percentages: 50% conversation, 10% tools, etc. |
| 25 | Local Embedding Models | Support for MiniLM, Nomic, MPNet running locally (no API calls) |
| 26 | HTTP API + Cron | Local API for scheduled actions |
| 27 | Config TOML Migration | Replace config.json with alfred.toml |
| 28 | Observability & Logging | Structured logging, tracing, metrics |

### Long-term ðŸ”®

| # | Milestone | Description |
|---|-----------|-------------|
| 29 | Vector Database Evaluation | SQLite-vec or Chroma if JSONL performance degrades |
| 30 | Multi-user Support | Proper user isolation and authentication |
| 31 | Plugin System | Extensible tool and skill architecture |

---

## Development TODOs

### UI/UX Improvements
- [ ] **Add Shift+Enter to queue message** - Allow queuing messages while LLM is running
- [ ] **Normal Enter is steering mode** - Interject with it instead of waiting for completion
- [ ] **Add background color to tool call output** - Better visual distinction for tool calls
- [ ] **Keybind to toggle tool call output** - Show/hide tool call sections
- [ ] **Create PRD for ESC keybinding** - Add keyboard shortcut to cancel the current LLM call

### Reasoning & Agent Behavior
- [ ] **Remove max iterations limit** - Agent should run until completion or user cancellation
- [ ] **Investigate reasoning traces** - Save reasoning only for immediate previous turn, summarize/discard for older turns

### Edit Tool Safety
- [ ] **Ensure edit tool forces exact text matching**
  - Current issue: LLM sometimes guesses file state
  - Solution: Validate `oldText` matches current content exactly
  - Reject with clear error if mismatch detected
- [ ] **Add pre-edit validation**
  - Read file immediately before each edit
  - Compare against `oldText` parameter
  - Provide diff output when mismatch occurs

### Test Configuration
- [ ] **Skip integration and e2e tests during regular pytest runs**
  - Mark with `@pytest.mark.integration` / `@pytest.mark.e2e`
  - Configure `pyproject.toml` to exclude by default
- [ ] **Configure CI to run integration and e2e tests separately**
  - Keep unit tests fast for development feedback

### Code Quality
- [ ] **Fix pytest deprecation warnings**
  - `asyncio.iscoroutinefunction` â†’ `inspect.iscoroutinefunction()`
  - Pydantic class-based `config` â†’ `ConfigDict`
  - Register custom marks in `pyproject.toml`

---

## Success Criteria

- [ ] Alfred recalls conversations from any prior session
- [ ] Semantic search returns >80% relevant results
- [ ] Response latency under 5 seconds (streaming start)
- [ ] Zero data loss across restarts
- [ ] All tests passing with >80% coverage
- [ ] Documentation complete for contributors

---

## Environment Variables

```bash
# Required
TELEGRAM_BOT_TOKEN=xxx
OPENAI_API_KEY=xxx
KIMI_API_KEY=xxx
KIMI_BASE_URL=https://api.kimi.com/coding/v1

# Optional
DEFAULT_LLM_PROVIDER=kimi
MEMORY_CONTEXT_LIMIT=20
EMBEDDING_MODEL=text-embedding-3-small
```

---

## Decision Log

| Date | Decision | Rationale |
|------|----------|-----------|
| 2026-02-17 | JSONL over per-day files | Simpler, unified search, easier CRUD |
| 2026-02-17 | Single user, single agent | MVP simplicity |
| 2026-02-18 | Tool system with Pydantic | Automatic schema generation, validation |
| 2026-02-18 | Streaming agent loop | Real-time feedback, better UX |
| 2026-02-19 | Prompt-based learning | Learning is judgment-based; tools for deterministic ops |
| 2026-02-19 | Templates â†’ data/ | Keeps templates clean, allows user reset |
| 2026-02-19 | Model-driven memory | Alfred decides what to remember, not automatic logging |
| 2026-02-19 | In-memory sessions | PRD #54; persistence planned for PRD #53 |
| 2026-02-20 | Rich Live for CLI markdown | Proper in-place markdown rendering without scrollback pollution |

---

## Notes

- Keep all memories forever (no automatic pruning)
- No encryption at rest (for now)
- Local development with Docker Compose
- Pre-commit hooks for code quality
- Stay with JSONL until search latency >100ms, then consider SQLite-vec
