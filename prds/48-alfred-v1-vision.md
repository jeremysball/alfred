# PRD: Alfred v1.0 - Complete Vision

## Overview

**Issue**: #48
**Status**: PERMANENT
**Priority**: High
**Created**: 2026-02-18
**Supersedes**: #10

Alfred is a persistent memory-augmented LLM assistant. He remembers conversations across sessions, learns user preferences over time, and builds genuine understanding through accumulated context.

---

## Problem Statement

Existing LLM assistants start fresh every conversation. Users repeat themselves, lose context, and cannot build lasting relationships. Alfred solves this by maintaining persistent memory that grows richer over time.

---

## Solution Overview

### Core Concept
Alfred runs locally, speaks through Telegram or CLI, and uses a file-based memory system with vector embeddings for semantic retrieval.

### Key Differentiators
1. **Persistent Memory**: Every conversation stored with embeddings for semantic search
2. **Curated Knowledge**: MEMORY.md holds distilled, high-value insights
3. **Tool System**: Built-in tools for reading, writing, editing, and bash execution
4. **Streaming Agent Loop**: Real-time responses with tool execution visibility
5. **Model Agnostic**: Pluggable LLM providers (Kimi, OpenAI, etc.)
6. **File-Based Context**: Human-readable configuration (SOUL.md, USER.md, TOOLS.md)

---

## Design Principles

### 1. Model-Driven Intelligence
When Alfred makes decisionsâ€”what to remember, how to respond, which tool to useâ€”the LLM decides. Prefer prompting over programming.

### 2. Zero-Command Interface
Users speak naturally. "What did we discuss about my project?" triggers semantic search automatically. No `/commands` required for core functionality.

### 3. Fail Fast
Errors surface immediately. Silent failures hide bugs. Memories without embeddings are rejected.

### 4. Streaming First
Users see responses in real-time. Tool execution happens visibly. No waiting for complete responses.

---

## Technical Architecture

### Technology Stack
- **Runtime**: Python 3.12+ with `uv`
- **Interfaces**: Telegram Bot API (async), CLI
- **Container**: Docker with Tailscale networking
- **Storage**: JSONL files with OpenAI embeddings
- **Search**: Cosine similarity on vector embeddings

### File Structure
```
alfred/
â”œâ”€â”€ AGENTS.md              # Agent behavior rules
â”œâ”€â”€ SOUL.md               # Alfred's personality
â”œâ”€â”€ USER.md               # User preferences
â”œâ”€â”€ TOOLS.md              # LLM/environment config
â”œâ”€â”€ MEMORY.md             # Curated long-term memory
â”œâ”€â”€ templates/            # Auto-created context templates
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ alfred.py         # Core engine
â”‚   â”œâ”€â”€ agent.py          # Streaming agent loop
â”‚   â”œâ”€â”€ llm.py            # Provider abstraction
â”‚   â”œâ”€â”€ memory.py         # Memory store (JSONL + embeddings)
â”‚   â”œâ”€â”€ context.py        # Context assembly
â”‚   â”œâ”€â”€ embeddings.py     # OpenAI embeddings
â”‚   â”œâ”€â”€ search.py         # Semantic search
â”‚   â”œâ”€â”€ templates.py      # Template auto-creation
â”‚   â”œâ”€â”€ tools/            # Tool implementations
â”‚   â”‚   â”œâ”€â”€ base.py       # Tool abstract class
â”‚   â”‚   â”œâ”€â”€ read.py       # File reading
â”‚   â”‚   â”œâ”€â”€ write.py      # File writing
â”‚   â”‚   â”œâ”€â”€ edit.py       # File editing
â”‚   â”‚   â”œâ”€â”€ bash.py       # Shell execution
â”‚   â”‚   â”œâ”€â”€ remember.py   # Save to memory
â”‚   â”‚   â”œâ”€â”€ search_memories.py
â”‚   â”‚   â”œâ”€â”€ update_memory.py
â”‚   â”‚   â””â”€â”€ forget.py     # Delete memories
â”‚   â””â”€â”€ interfaces/
â”‚       â”œâ”€â”€ cli.py        # CLI interface
â”‚       â””â”€â”€ telegram.py   # Telegram bot
â”œâ”€â”€ data/
â”‚   â””â”€â”€ memories.jsonl    # Unified memory store
â””â”€â”€ tests/
```

### Core Components

#### 1. Alfred Engine (`src/alfred.py`)
Orchestrates memory, context, LLM, and agent loop. Entry point for all interfaces.

#### 2. Agent Loop (`src/agent.py`)
Streaming agent that coordinates LLM and tool execution. Handles tool call parsing, execution, and result injection.

#### 3. Memory System (`src/memory.py`)
Unified JSONL storage with embeddings. Supports:
- **Add**: Store new memories with auto-generated embeddings
- **Search**: Semantic search by similarity Ã— importance
- **Update**: Modify content or importance
- **Delete**: Remove by ID or semantic query
- **Curated**: Read/write MEMORY.md for long-term knowledge

#### 4. Tool System (`src/tools/`)
Pydantic-validated tools with automatic JSON schema generation:
- **ReadTool**: Read file contents
- **WriteTool**: Create or overwrite files
- **EditTool**: Surgical file edits
- **BashTool**: Execute shell commands
- **RememberTool**: Save memories
- **SearchMemoriesTool**: Semantic memory search
- **UpdateMemoryTool**: Modify existing memories
- **ForgetTool**: Delete memories

#### 5. Context Assembly (`src/context.py`)
Loads and assembles system prompt from:
- AGENTS.md (behavior rules)
- SOUL.md (personality)
- USER.md (user profile)
- TOOLS.md (available tools)
- Retrieved memories (top-k relevant)

---

## Memory Systems

### 1. Conversation Memory (Automatic)
Every interaction stored in `data/memories.jsonl` with:
- Timestamp, role, content
- OpenAI embedding vector
- Importance score (0.0-1.0)
- Tags for categorization

### 2. Curated Memory (MEMORY.md)
High-value knowledge manually or automatically distilled. Loaded into every context.

### 3. Semantic Retrieval
Query embedding compared against all memory embeddings. Results ranked by:
```
score = cosine_similarity Ã— (0.7 + 0.3 Ã— importance)
```

---

## Roadmap to v1.0

| # | Milestone | Status | Description |
|---|-----------|--------|-------------|
| M1 | Project Setup | âœ… Done | Repository, tooling, CI/CD |
| M2 | Core Infrastructure | âœ… Done | Config, context, templates |
| M3 | Memory Foundation | âœ… Done | JSONL storage, embeddings |
| M4 | Vector Search | âœ… Done | Semantic retrieval |
| M5 | Interfaces | âœ… Done | CLI + Telegram |
| M6 | Kimi Provider | âœ… Done | Moonshot AI integration |
| M7 | Tool System | âœ… Done | Built-in tools with schemas |
| M8 | Agent Loop | âœ… Done | Streaming with tool execution |
| M9 | Distillation | ðŸ”² Todo | Auto-extract insights to MEMORY.md |
| M10 | Learning | ðŸ”² Todo | Auto-update USER.md from patterns |
| M11 | Compaction | ðŸ”² Todo | Summarize long conversations |
| M12 | Testing | ðŸ”² Todo | Comprehensive test coverage |
| M13 | Documentation | ðŸ”² Todo | API docs, architecture guide |

---

## Success Criteria

- [ ] Alfred recalls conversations from any prior session
- [ ] Semantic search returns >80% relevant results
- [ ] Response latency under 5 seconds (streaming start)
- [ ] Zero data loss across restarts
- [ ] All tests passing with >80% coverage
- [ ] Documentation complete for contributors

---

## Environment Variables

```bash
# Required
TELEGRAM_BOT_TOKEN=xxx
OPENAI_API_KEY=xxx
KIMI_API_KEY=xxx
KIMI_BASE_URL=https://api.moonshot.cn/v1

# Optional
DEFAULT_LLM_PROVIDER=kimi
MEMORY_CONTEXT_LIMIT=20
EMBEDDING_MODEL=text-embedding-3-small
```

---

## Dependencies

| Package | Purpose |
|---------|---------|
| `python-telegram-bot` | Telegram Bot API |
| `openai` | Embeddings |
| `httpx` | HTTP client for LLM providers |
| `pydantic` | Data validation |
| `aiofiles` | Async file operations |
| `python-dotenv` | Environment loading |

---

## Decision Log

| Date | Decision | Rationale |
|------|----------|-----------|
| 2026-02-17 | JSONL over per-day files | Simpler, unified search, easier CRUD |
| 2026-02-17 | MEMORY.md over IMPORTANT.md | Matches OpenClaw pattern |
| 2026-02-17 | Single user, single agent | MVP simplicity |
| 2026-02-18 | Tool system with Pydantic | Automatic schema generation, validation |
| 2026-02-18 | Streaming agent loop | Real-time feedback, better UX |

---

## Notes

- Keep all memories forever (no automatic pruning)
- No encryption at rest (for now)
- Local development with Docker Compose
- Pre-commit hooks for code quality
