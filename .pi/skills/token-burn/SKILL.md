---
name: token-burn
description: Calculate total token usage from pi session JSONL files with beautiful emoji tables. Use when analyzing conversation history, tracking API costs, or auditing token consumption.
---

# ğŸ”¥ Token Burn

Calculate token usage from pi session JSONL files with beautiful visual output. Extracts actual token counts including cached tokens (cacheRead, cacheWrite) from message metadata.

![Token Burn Demo](assets/demo.png)

## âœ¨ Features

| Feature | Status | Emoji |
|---------|--------|-------|
| Beautiful emoji-enhanced tables | âœ… | ğŸ“Š |
| Stream large JSONL files | âœ… | ğŸŒŠ |
| Extract cached tokens | âœ… | ğŸ’¾ |
| Model detection with icons | âœ… | ğŸ¤– |
| Recursive directory processing | âœ… | ğŸ“ |
| JSON output format | âœ… | ğŸ“‹ |
| Cost estimation guidance | âœ… | ğŸ’° |

## ğŸš€ Quick Start

```bash
cd /workspace/.pi/skills/token-burn

# ğŸ”¥ Run with default path (~/.pi/agent/sessions)
python3 src/token_burn.py

# ğŸ“„ Process specific session file
python3 src/token_burn.py ~/.pi/agent/sessions/--workspace--/2026-02-18.jsonl

# ğŸ“ Process all sessions recursively
python3 src/token_burn.py ~/.pi/agent/sessions --recursive

# ğŸ“‹ Output as JSON
python3 src/token_burn.py --json
```

## ğŸ“– Usage Examples

### Default Session Analysis
```bash
# Analyzes ~/.pi/agent/sessions by default
python3 src/token_burn.py
```

**Output:**
```
ğŸ”¥â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ğŸ”¥
â•‘                    ğŸ’° TOKEN BURN REPORT ğŸ’°                         â•‘
ğŸ”¥â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ğŸ”¥

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ğŸ“Š  Session Summary                                                 â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  ğŸ“ Files Processed              84                                â•‘
â•‘  ğŸ“„ Total Lines              11,561                                â•‘
â•‘  ğŸ’¬ Messages w/ Usage         4,899                                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### JSON Output for Automation
```bash
python3 src/token_burn.py --json > token_report.json
```

## ğŸ“Š Output Format Details

### Model Emojis

| Provider | Emoji | Example Models |
|----------|-------|----------------|
| Kimi | ğŸŒ™ | kimi-coding/k2p5, kimi-k2-thinking |
| Claude | ğŸ§  | claude-4-sonnet, claude-opus-4 |
| OpenAI | ğŸ¤– | o1, o3-mini, gpt-4o |
| Gemini | ğŸ’ | gemini-2.0-flash-thinking |
| GLM/Zhipu | âš¡ | glm-4, glm-5 |
| DeepSeek | ğŸ”® | deepseek-r1, deepseek-reasoner |
| Qwen | ğŸ‰ | qwen-qwq |
| Unknown | ğŸ¤– | fallback for unrecognized models |

### Token Types

| Token Type | Emoji | Description |
|------------|-------|-------------|
| `input` | ğŸ“¥ | Standard input tokens sent to API |
| `output` | ğŸ“¤ | Generated output tokens from model |
| `cacheRead` | ğŸ’¾ | Tokens read from cache (cheaper) |
| `cacheWrite` | ğŸ’¿ | Tokens written to cache (one-time cost) |

## ğŸ’° Cost Estimation with Search Skills

Token Burn integrates with search skills to estimate actual costs:

### Step 1: Get Token Counts
```bash
python3 src/token_burn.py
```

### Step 2: Search for Current Pricing

```bash
# For Claude/Anthropic models
serper-search "Anthropic Claude API pricing per token 2025"

# For OpenAI models  
serper-search "OpenAI o1 API pricing per million tokens 2025"

# For Kimi models
serper-search "Moonshot AI Kimi k2 API pricing 2025"
```

### Step 3: Calculate Estimated Cost

```
Model: kimi-coding/k2p5
Input tokens:      11,065,261
Output tokens:      1,082,103
Cache read:       239,416,576

Pricing (example):
- Input:   $0.50/1M
- Output:  $1.50/1M
- Cache read: $0.05/1M (usually much cheaper)

Cost = (11.07M Ã— $0.50) + (1.08M Ã— $1.50) + (239.42M Ã— $0.05)
     = $5.54 + $1.62 + $11.97
     = $19.13
```

## ğŸ”§ Advanced Usage

### Process Specific Workspace
```bash
python3 src/token_burn.py ~/.pi/agent/sessions/--workspace-alfred-- --recursive
```

### Filter by Date Range
```bash
find ~/.pi/agent/sessions -name "2026-02-18*.jsonl" -exec \
  python3 src/token_burn.py {} \;
```

## ğŸ› ï¸ How It Works

1. **ğŸŒŠ Streaming**: Reads JSONL files line-by-line without loading into memory
2. **ğŸ” Model Detection**: Extracts provider/model from message metadata  
3. **ğŸ“Š Token Extraction**: Extracts `input`, `output`, `cacheRead`, `cacheWrite`
4. **ğŸ§® Aggregation**: Sums tokens by model and calculates grand totals
5. **ğŸ¨ Beautiful Output**: Renders emoji-enhanced tables with smart formatting

## ğŸ”— Integration with Other Skills

| Skill | Use Case | Command Example |
|-------|----------|-----------------|
| serper-search | Find current API pricing | `serper-search "Claude API pricing 2025"` |
| writing-clearly | Document findings | Use for cost reports |

## ğŸ“ License

MIT Â© 2025 Token Burn Project
