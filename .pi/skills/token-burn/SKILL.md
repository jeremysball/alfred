---
name: token-burn
description: Calculate total token usage from pi session JSONL files with beautiful emoji tables. Use when analyzing conversation history, tracking API costs, or auditing token consumption across multiple sessions. Integrates with search skills for cost estimation.
---

# ğŸ”¥ Token Burn

Calculate token usage from pi session JSONL files with beautiful visual output. Extracts actual token counts including cached tokens (cacheRead, cacheWrite) from message metadata.

![Token Burn Demo](assets/demo.png)

## âœ¨ Features

| Feature | Status | Emoji |
|---------|--------|-------|
| Beautiful emoji-enhanced tables | âœ… | ğŸ“Š |
| Stream large JSONL files | âœ… | ğŸŒŠ |
| Extract cached tokens | âœ… | ğŸ’¾ |
| Model detection with icons | âœ… | ğŸ¤– |
| Recursive directory processing | âœ… | ğŸ“ |
| JSON output format | âœ… | ğŸ“‹ |
| Cost estimation guidance | âœ… | ğŸ’° |

## ğŸš€ Quick Start

```bash
cd /workspace/.pi/skills/token-burn

# ğŸ”¥ Run with default path (~/.pi/agent/sessions)
python3 src/token_burn.py

# ğŸ“„ Process specific session file
python3 src/token_burn.py ~/.pi/agent/sessions/--workspace--/2026-02-18.jsonl

# ğŸ“ Process all sessions recursively
python3 src/token_burn.py ~/.pi/agent/sessions --recursive

# ğŸ“‹ Output as JSON
python3 src/token_burn.py --json
```

## ğŸ“– Usage Examples

### Default Session Analysis
```bash
# Analyzes ~/.pi/agent/sessions by default
python3 src/token_burn.py
```

**Output:**
```
ğŸ”¥â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ğŸ”¥
â•‘                    ğŸ’° TOKEN BURN REPORT ğŸ’°                         â•‘
ğŸ”¥â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ğŸ”¥

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ğŸ“Š  Session Summary                                                 â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  ğŸ“ Files Processed              84                                â•‘
â•‘  ğŸ“„ Total Lines              11,561                                â•‘
â•‘  ğŸ’¬ Messages w/ Usage         4,899                                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ğŸ“Š
â•‘              ğŸ¤– TOKEN USAGE BY MODEL ğŸ¤–                            â•‘
ğŸ“Šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ğŸ“Š

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ #1  ğŸŒ™  kimi-coding/k2p5                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ“¥  Input:             11,065,261  (11.07M)    44.5%              â”‚
â”‚  ğŸ“¤  Output:             1,082,103  (1.08M)      4.4%              â”‚
â”‚  ğŸ’¾  Cache Read:       239,416,576  (239.42M)   95.1%              â”‚
â”‚  ğŸ’¿  Cache Write:               0  (0)           0.0%              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ”¥  TOTAL:            251,563,940  (251.56M)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ’°â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ğŸ’°
â•‘                    ğŸ† GRAND TOTALS ğŸ†                              â•‘
ğŸ’°â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ğŸ’°
â”‚  ğŸ“¥  TOTAL INPUT          16,191,416  (16.19M)                     â”‚
â”‚  ğŸ“¤  TOTAL OUTPUT          1,334,843  (1.33M)                      â”‚
â”‚  ğŸ’¾  TOTAL CACHE READ    270,346,440  (270.35M)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ”¥  GRAND TOTAL         287,872,699  (287.87M)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ’¡â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ğŸ’¡
â”‚  ğŸ’° Cost Estimation Tip:                                           â”‚
â”‚     Use serper-search or web-search to find current pricing:       â”‚
â”‚     'Anthropic Claude API pricing per token 2025'                  â”‚
â”‚     'OpenAI GPT-4 pricing per token 2025'                          â”‚
â”‚     Then multiply: tokens Ã— price_per_token = estimated cost       â”‚
ğŸ’¡â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ğŸ’¡
```

### JSON Output for Automation
```bash
python3 src/token_burn.py --json > token_report.json
```

## ğŸ’° Cost Estimation with Search Skills

Token Burn integrates beautifully with search skills to estimate actual costs:

### Step 1: Get Token Counts
```bash
python3 src/token_burn.py
# Note the model names and token counts (e.g., kimi-coding/k2p5: 251M tokens)
```

### Step 2: Search for Current Pricing

Use **serper-search** (or any web search skill) to find current pricing:

```bash
# For Claude/Anthropic models
serper-search "Anthropic Claude API pricing per token 2025"

# For OpenAI models  
serper-search "OpenAI GPT-4o API pricing per million tokens 2025"

# For Kimi models
serper-search "Moonshot AI Kimi API pricing per token 2025"

# For GLM/Zhipu models
serper-search "Zhipu AI GLM-4 API pricing per token 2025"
```

### Step 3: Calculate Estimated Cost

Example calculation:
```
Model: kimi-coding/k2p5
Input tokens:  11,065,261
Output tokens: 1,082,103

Pricing (hypothetical):
- Input:  $0.50 per 1M tokens
- Output: $1.50 per 1M tokens

Cost = (11.07M Ã— $0.50) + (1.08M Ã— $1.50)
     = $5.54 + $1.62
     = $7.16
```

### ğŸ” Quick Cost Lookup Commands

Add these to your workflow:

```bash
# Claude pricing
alias claude-pricing='serper-search "Anthropic Claude 3.5 Sonnet API pricing 2025"'

# OpenAI pricing  
alias openai-pricing='serper-search "OpenAI GPT-4o mini API pricing per million tokens"'

# Kimi pricing
alias kimi-pricing='serper-search "Moonshot AI Kimi k2 API pricing 2025"'
```

## ğŸ“Š Output Format Details

### Model Emojis

| Provider | Emoji | Example Models |
|----------|-------|----------------|
| Kimi | ğŸŒ™ | kimi-coding/k2p5, kimi-k2-thinking |
| Claude | ğŸ§  | claude-3.5-sonnet, claude-3-opus |
| OpenAI | ğŸ¤– | gpt-4o, gpt-4o-mini, gpt-3.5-turbo |
| Gemini | ğŸ’ | gemini-1.5-pro, gemini-1.5-flash |
| Zhipu/GLM | âš¡ | zai/glm-4, zai/glm-5 |
| Llama | ğŸ¦™ | llama-3.1-70b, llama-3.1-8b |
| DeepSeek | ğŸ”® | deepseek-chat, deepseek-coder |
| Unknown | ğŸ¤– | fallback for unrecognized models |

### Token Format

| Range | Display | Example |
|-------|---------|---------|
| < 1,000 | exact | `842` |
| 1K - 1M | K suffix | `12.5K` |
| â‰¥ 1M | M suffix | `251.56M` |

## ğŸ”§ Advanced Usage

### Process Specific Workspace
```bash
python3 src/token_burn.py ~/.pi/agent/sessions/--workspace-alfred-- --recursive
```

### Filter by Date Range (with find)
```bash
# Only sessions from today
find ~/.pi/agent/sessions -name "2026-02-18*.jsonl" -exec \
  python3 src/token_burn.py {} \;
```

### Compare Sessions
```bash
# Yesterday vs today
python3 src/token_burn.py ~/.pi/agent/sessions/--workspace--/2026-02-17*.jsonl --json > yesterday.json
python3 src/token_burn.py ~/.pi/agent/sessions/--workspace--/2026-02-18*.jsonl --json > today.json
```

## ğŸ“ JSON Output Structure

```json
{
  "files_processed": 84,
  "total_lines": 11561,
  "total_messages": 4899,
  "tokens_by_model": {
    "kimi-coding/k2p5": {
      "input": 11065261,
      "output": 1082103,
      "cache_read": 239416576,
      "cache_write": 0,
      "total": 251563940
    }
  },
  "total_input": 16191416,
  "total_output": 1334843,
  "total_cache_read": 270346440,
  "total_cache_write": 0,
  "total_tokens": 287872699
}
```

## ğŸ¯ Cached Token Support

| Token Type | Emoji | Description |
|------------|-------|-------------|
| `input` | ğŸ“¥ | Standard input tokens sent to API |
| `output` | ğŸ“¤ | Generated output tokens from model |
| `cacheRead` | ğŸ’¾ | Tokens read from cache (cheaper) |
| `cacheWrite` | ğŸ’¿ | Tokens written to cache (one-time cost) |

## ğŸ› ï¸ How It Works

1. **ğŸŒŠ Streaming**: Reads JSONL files line-by-line without loading into memory
2. **ğŸ” Model Detection**: Extracts provider/model from message metadata  
3. **ğŸ“Š Token Extraction**: Extracts `input`, `output`, `cacheRead`, `cacheWrite`
4. **ğŸ§® Aggregation**: Sums tokens by model and calculates grand totals
5. **ğŸ¨ Beautiful Output**: Renders emoji-enhanced tables with smart formatting

## ğŸ”— Integration with Other Skills

| Skill | Use Case | Command Example |
|-------|----------|-----------------|
| serper-search | Find current API pricing | `serper-search "Claude API pricing 2025"` |
| zai-web-search | Alternative pricing lookup | `zai-web-search "OpenAI GPT-4o pricing"` |
| writing-clearly | Document findings | Use for cost reports |

## ğŸ“ License

MIT Â© 2025 Token Burn Project
